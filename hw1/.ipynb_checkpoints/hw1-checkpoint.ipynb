{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning \n",
    "\n",
    "### Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b4751dd43b33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data = [[0,0,0,1,0,1,0],\n",
    "    [0,1,0,0,1,1,1],\n",
    "    [1,0,1,0,1,0,0],\n",
    "    [0,0,1,1,0,0,1],\n",
    "    [0,0,1,1,0,0,0]]\n",
    "\n",
    "old_data = np.array(old_data).T\n",
    "old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "for i,col in enumerate(old_data.T):\n",
    "    data_dict[i] = col\n",
    "    \n",
    "data = data_dict\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    \n",
    "    vals, freqs = np.unique(labels, return_counts=True)\n",
    "    probs = freqs / len(labels)\n",
    "    entropy = - probs.dot(np.log2(probs))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information Gain:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes three parameters:\n",
    "    1. data = The dataset for whose feature the IG should be calculated\n",
    "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
    "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
    "    \"\"\"    \n",
    "    #Calculate the entropy of the total dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    #Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(data,split_attr, target_attr):\n",
    "    \n",
    "  \n",
    "    total_entropy = entropy(data[target_attr])\n",
    "    \n",
    "    # Calculate the values and the corresponding counts for the split feature\n",
    "    vals, freqs = np.unique(data[split_attr] ,return_counts=True)\n",
    "    \n",
    "    # Calculate new entropy for split\n",
    "    new_entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "        indexes = np.where(data[split_attr]==vals[i])\n",
    "        new_entropy += (freqs[i]/np.sum(freqs))*entropy(data[target_attr][indexes])\n",
    "    \n",
    "    # Calculate information gain\n",
    "    info_gain = total_entropy - new_entropy\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0059777114237739015"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain(data,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3], dtype=int64),)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = np.where(data[4]==1)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4][indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data.values())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [1, 1, 0, 0],\n",
       "        [0, 1, 0, 1]]), array([0, 0, 1, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_data = old_data[:,:-1]\n",
    "labels = old_data[:,-1]\n",
    "\n",
    "attr_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "H(x1 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name='',value=None, children=None, parent=None):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.parent = parent\n",
    "        self.children = children or []\n",
    "\n",
    "    def add_child(self, value):\n",
    "        new_child = Node(value, parent=self)\n",
    "        self.children.append(new_child)\n",
    "        return new_child\n",
    "    \n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.children\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.value)\n",
    "        return '{value} [{children}]'.format(value=self.value, children=', '.join(map(str, self.children)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = data\n",
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict({'aa':11})\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, original_data, attrs, target_attr, parent_label, r_count):\n",
    "    \"\"\" ID3 Algorithm description\n",
    "    \n",
    "    Args:\n",
    "        data (dict): input data\n",
    "        original_data (numpy array): copy of original, untouched data \n",
    "        attrs (list): list of integers of attributes, all but the target attribute\n",
    "        target_attr (int): integer corresponding to column index of target attribute labels\n",
    "        parent_label (int): attribute label of parent node in recursive algorithm.\n",
    "        \n",
    "    Returns:\n",
    "  \n",
    "    \"\"\"\n",
    "    r_count+=1\n",
    "    #print(r_count)\n",
    "    \n",
    "    labels = np.array(list(data.values())[-1])\n",
    "    \n",
    "    print('{}: data: {}'.format(r_count, data))\n",
    "    # if all target labels are the same, stop and return this value\n",
    "    unique_labels = np.unique(data[target_attr])\n",
    "    if len(unique_labels) == 1:\n",
    "        print('All rows the same! return: '.format(unique_labels[0]))\n",
    "        return unique_labels[0]\n",
    "    \n",
    "    # if the data is empty, return the label that occurs the most in the origional data\n",
    "    elif len(data) == 0:\n",
    "        print('data empty!')\n",
    "        vals, freqs = np.unique(original_data[target_attr],return_counts=True)\n",
    "        return np.unique(original_data[target_attr])[np.argmax(freqs)]\n",
    "\n",
    "    # if there are no more attributes, return the parent label\n",
    "    elif len(attrs) == 0:\n",
    "        print('Out of features')\n",
    "        return parent_label\n",
    "    else:\n",
    "        # set default value for this node to the mode of the target feature values\n",
    "        vals, freqs = np.unique(data[target_attr],return_counts=True)\n",
    "        parent_label = np.unique(data[target_attr])[np.argmax(freqs)]\n",
    "        \n",
    "        print('{}: remaing attrs: {}'.format(r_count, attrs))\n",
    "        # Find best attribute to split data on\n",
    "        info_gains = [info_gain(data,i, target_attr) for i in attrs]\n",
    "        best_attr = attrs[info_gains.index(max(info_gains))]\n",
    "        \n",
    "        print('{}: Best Attr: {}'.format(r_count, best_attr))\n",
    "        \n",
    "        # create new subtree\n",
    "        tree = dict()\n",
    "        tree[best_attr] = dict()\n",
    "        \n",
    "        # remove best attribute from attribute list\n",
    "        attrs = [i for i in attrs if i != best_attr]\n",
    "\n",
    "        # grow tree\n",
    "        for val in np.unique(data[best_attr]):\n",
    "            val = val\n",
    "            new_data = dict(data)\n",
    "            \n",
    "            print('   {}: val: {}: '.format(r_count, val))\n",
    "            \n",
    "            # split dataset on the best attribute and remove this column from dataset\n",
    "            \n",
    "            indexes = np.where(new_data[best_attr]== val)\n",
    "            for key, v in new_data.items():\n",
    "                new_data[key] = np.delete(new_data[key], indexes)\n",
    "                \n",
    "            new_data.pop(best_attr)\n",
    "            #new_data = data[]\n",
    "            #new_data = np.delete(new_data, best_attr, axis=1)\n",
    "            \n",
    "            #print('New Data Size: {}'.format(np.size(new_data)))\n",
    "            \n",
    "            #print('   {}: val: {}: Subdata: {}'.format(r_count, val, new_data))\n",
    "            \n",
    "            # Recursion \n",
    "            new_tree = id3(new_data, original_data, attrs, target_attr, parent_label, r_count)\n",
    "            \n",
    "            # Add subtree to parents tree\n",
    "            tree[best_attr][val] = new_tree\n",
    "\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "for i,col in enumerate(old_data.T):\n",
    "    data_dict[i] = col\n",
    "    \n",
    "data = data_dict\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-143-b8b95de87ef7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-143-b8b95de87ef7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    a == not 1\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a == not 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_attr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3], dtype=int64),)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = np.where(data[best_attr]==0)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, v in data.items():\n",
    "    data[key] = np.delete(data[key], indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 1, 0]),\n",
       " 1: array([1, 1, 1, 1]),\n",
       " 2: array([0, 1, 0, 0]),\n",
       " 3: array([0, 0, 0, 1]),\n",
       " 4: array([0, 0, 0, 0])}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pop(best_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 1, 0]),\n",
       " 2: array([0, 1, 0, 0]),\n",
       " 3: array([0, 0, 0, 1]),\n",
       " 4: array([0, 0, 0, 0])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(data[1]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1] = np.delete(data[1], ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([1, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[np.where(data[:,3]==0)]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = [i for i in attrs if i != 2]\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 6], dtype=int64),)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(data[3]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-1ecca6434c20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**TESTING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 1, 0, 1, 0]),\n",
       " 1: array([0, 1, 0, 0, 1, 1, 1]),\n",
       " 2: array([1, 0, 1, 0, 1, 0, 0]),\n",
       " 3: array([0, 0, 1, 1, 0, 0, 1]),\n",
       " 4: array([0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "for i,col in enumerate(old_data.T):\n",
    "    data_dict[i] = col\n",
    "    \n",
    "data = data_dict\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: data: {0: array([0, 0, 0, 1, 0, 1, 0]), 1: array([0, 1, 0, 0, 1, 1, 1]), 2: array([1, 0, 1, 0, 1, 0, 0]), 3: array([0, 0, 1, 1, 0, 0, 1]), 4: array([0, 0, 1, 1, 0, 0, 0])}\n",
      "1: remaing attrs: [0, 1, 2, 3]\n",
      "1: Best Attr: 1\n",
      "   1: val: 0: \n",
      "2: data: {0: array([0, 0, 1, 0]), 2: array([0, 1, 0, 0]), 3: array([0, 0, 0, 1]), 4: array([0, 0, 0, 0])}\n",
      "All rows the same! return: \n",
      "   1: val: 1: \n",
      "2: data: {0: array([0, 0, 1]), 2: array([1, 1, 0]), 3: array([0, 1, 1]), 4: array([0, 1, 1])}\n",
      "2: remaing attrs: [0, 2, 3]\n",
      "2: Best Attr: 3\n",
      "   2: val: 0: \n",
      "3: data: {0: array([0, 1]), 2: array([1, 0]), 4: array([1, 1])}\n",
      "All rows the same! return: \n",
      "   2: val: 1: \n",
      "3: data: {0: array([0]), 2: array([1]), 4: array([0])}\n",
      "All rows the same! return: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {0: 0, 1: {3: {0: 1, 1: 0}}}}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id3(data, original_data=data, attrs=[0,1,2,3], target_attr=4, parent_label=None, r_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 1, 0]),\n",
       " 2: array([0, 1, 0, 0]),\n",
       " 3: array([0, 0, 0, 1]),\n",
       " 4: array([0, 0, 0, 0])}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs=[0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0,0,0,1,0,1,0],\n",
    "    [0,1,0,0,1,1,1],\n",
    "    [1,0,1,0,1,0,0],\n",
    "    [0,0,1,1,0,0,1],\n",
    "    [0,0,1,1,0,0,0]]\n",
    "\n",
    "data = np.array(data).T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_data = data[:,:-1]\n",
    "labels = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, freqs = np.unique(data[:,-1],return_counts=True)\n",
    "parent_label = np.unique(data[:,-1])[np.argmax(freqs)]\n",
    "        \n",
    "vals, freqs, parent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best attribute to split data on\n",
    "info_gains = [info_gain(data,i) for i in attrs]\n",
    "best_attr = info_gains.index(max(info_gains))\n",
    "        \n",
    "info_gains, best_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new subtree\n",
    "tree = dict()\n",
    "tree[best_attr] = dict()\n",
    "        \n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[best_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove best attribute from attribute list\n",
    "attrs = [i for i in attrs if i != best_attr]\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "\n",
    "\n",
    "val = val\n",
    "            \n",
    "new_data = data[np.where(data[:,best_attr]==val)]\n",
    "print('New Data Size: {}'.format(np.size(new_data)))\n",
    "            \n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursion \n",
    "new_tree = id3(new_data, original_data, attrs, target_attr, parent_label, r_count)\n",
    "            \n",
    "# Add subtree to parents tree\n",
    "tree[best_attr][val] = new_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array([[1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [0,0,0]]).T\n",
    "\n",
    "data = test1\n",
    "original_data = data\n",
    "\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3(data, original_data, attrs=[0,1,2,3], target_attr=4, parent_label=None, r_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = np.array([[1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [0,0,1]]).T\n",
    "\n",
    "data = test2\n",
    "original_data = data\n",
    "\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3(data, original_data=data, attrs=[0,1,2], target_attr=3, parent_label=None, r_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.array([[1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [1,1,1],\n",
    "                  [0,0,1]]).T\n",
    "\n",
    "data = test3\n",
    "original_data = data\n",
    "\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3(data, original_data, attrs=[], target_attr=3, parent_label=None, r_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm: This function takes five paramters:\n",
    "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
    " \n",
    "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
    "    in the case the dataset delivered by the first parameter is empty\n",
    "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
    "    we have to remove features from our dataset --> Splitting at each node\n",
    "    4. target_attribute_name = the name of the target attribute\n",
    "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is \n",
    "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
    "    space, we want to return the mode target feature value of the direct parent node.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "    #If all target_values have the same value, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
    "    #the mode target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mode target feature value of the current node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        \n",
    "        #Select the feature which best splits the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
    "        #gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Node(12)\n",
    "a = n.add_child(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[:,1]\n",
    "e = [0,0,0,0,0,0,0]\n",
    "d,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 4],\n",
       "       [5, 7, 8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.delete(a, 1, axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.321928094887362"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
