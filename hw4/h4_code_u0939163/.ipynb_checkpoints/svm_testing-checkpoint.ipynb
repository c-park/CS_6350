{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Implementations\n",
    "\n",
    "## Machine Learning, University of Utah\n",
    "\n",
    "### Cade Parkison\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('bank-note/test.csv', header=None)\n",
    "train_data = pd.read_csv('bank-note/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 7 columns are features, last column (Slump) is output\n",
    "columns = ['var', 'skew', 'curt', 'ent', 'label']\n",
    "features = columns[:-1]\n",
    "output = columns[-1]\n",
    "\n",
    "test_data.columns = columns\n",
    "train_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>curt</th>\n",
       "      <th>ent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.848100</td>\n",
       "      <td>10.15390</td>\n",
       "      <td>-3.85610</td>\n",
       "      <td>-4.22280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.004700</td>\n",
       "      <td>0.45937</td>\n",
       "      <td>1.36210</td>\n",
       "      <td>1.61810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-1.60370</td>\n",
       "      <td>8.47560</td>\n",
       "      <td>0.75558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266700</td>\n",
       "      <td>2.81830</td>\n",
       "      <td>-2.42600</td>\n",
       "      <td>-1.88620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.203400</td>\n",
       "      <td>5.99470</td>\n",
       "      <td>0.53009</td>\n",
       "      <td>0.84998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        var      skew     curt      ent  label\n",
       "0  3.848100  10.15390 -3.85610 -4.22280      0\n",
       "1  4.004700   0.45937  1.36210  1.61810      0\n",
       "2 -0.048008  -1.60370  8.47560  0.75558      0\n",
       "3 -1.266700   2.81830 -2.42600 -1.88620      1\n",
       "4  2.203400   5.99470  0.53009  0.84998      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data.iloc[:,:-1].values\n",
    "test_X = test_data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((872, 4), (500, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.iloc[:,-1].values\n",
    "test_y = test_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((872,), (500,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to {-1,1}\n",
    "train_y = np.array([1 if x else -1 for x in train_y])\n",
    "test_y = np.array([1 if x else -1 for x in test_y])\n",
    "\n",
    "# reshape to 2D array\n",
    "train_y = train_y.reshape(-1,1)\n",
    "test_y = test_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((872, 1), (500, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, epoch, C, rate_schedule):\n",
    "        self.epoch = epoch\n",
    "        self.C = C\n",
    "        self.rate_schedule = rate_schedule\n",
    "        self.weights = np.zeros(no_of_inputs + 1)  # initialize weights to zero\n",
    "           \n",
    "    def predict(self, X):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        return np.sign(np.dot(X, self.weights[:-1]) + self.weights[-1])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \n",
    "        N = y.shape[0]\n",
    "        \n",
    "        #labels = np.expand_dims(labels, axis=1)\n",
    "        data = np.hstack((X,y))\n",
    "        \n",
    "        for e in range(self.epoch):\n",
    "            #print(\"Epoch: \"+ str(e))\n",
    "            #print(\"Weights: \" + str(self.weights))\n",
    "            #print('')\n",
    "            rate = self.rate_schedule(e)\n",
    "            np.random.shuffle(data)\n",
    "            for i,row in enumerate(data):\n",
    "                x = row[:-1]\n",
    "                y = row[-1]\n",
    "                val = y*(np.dot(x, self.weights[:-1]) + self.weights[-1])\n",
    "                if val <= 1:\n",
    "                    self.weights[:-1] = (1-rate)*self.weights[:-1] + rate*self.C*N*y*x\n",
    "                    self.weights[-1] = rate*self.C*N*y\n",
    "                else:\n",
    "                    self.weights[:-1] = (1-rate)*self.weights[:-1]\n",
    "                    \n",
    "        return self.weights\n",
    "                \n",
    "    def evaluate(self, X, y):\n",
    "        # calculates average prediction error on testing dataset\n",
    "        errors = []\n",
    "        for inputs, label in zip(X, y):\n",
    "            prediction = self.predict(inputs)\n",
    "            if np.sign(prediction) != label:\n",
    "                errors.append(1)\n",
    "            else:\n",
    "                errors.append(0)\n",
    "        \n",
    "        return 100*(sum(errors) / float(X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "**Part a:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\gamma_t = \\frac{\\gamma_0}{1 + \\frac{\\gamma_0}{d} t} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_0 = 0.001\n",
    "d = 0.01\n",
    "\n",
    "schedule_a = lambda t:gamma_0 / (1 + (gamma_0/d)*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [1.0/873, 10.0/873, 50.0/873, 100.0/873, 300.0/873, 500.0/873, 700.0/873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0389908256880734"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1 = SVM(4, 100, 100/873, schedule_a)\n",
    "svm_1.train(train_X, train_y)\n",
    "svm_1.evaluate(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001145475372279496: weights = [-3.74999012e-01 -1.71782612e-01 -1.46115309e-01 -7.80712244e-02\n",
      "  9.16380298e-05]\n",
      "C 0.011454753722794959: weights = [-0.74050692 -0.37308407 -0.37429121 -0.19790761 -0.00091638]\n",
      "C 0.0572737686139748: weights = [-1.13026463 -0.55535113 -0.69693188 -0.31042097  0.0045819 ]\n",
      "C 0.1145475372279496: weights = [-1.44720154 -0.71534303 -0.80515422 -0.32493326  0.0091638 ]\n",
      "C 0.3436426116838488: weights = [-2.00728194 -1.1476715  -1.04464131 -0.68690303  0.02749141]\n",
      "C 0.572737686139748: weights = [-2.62307216 -1.73517131 -1.29206735 -1.02332767  0.04581901]\n",
      "C 0.8018327605956472: weights = [-3.42848911 -2.24249739 -1.97210138 -0.83556891 -0.06414662]\n",
      "Training Errors: [5.045871559633028, 4.128440366972478, 5.045871559633028, 4.013761467889909, 4.81651376146789, 5.5045871559633035, 4.81651376146789]\n",
      "Testing Errors: [7.199999999999999, 4.8, 6.4, 4.8, 5.6000000000000005, 6.800000000000001, 7.000000000000001]\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "for c in C_list:\n",
    "    svm = SVM(4, 100, c, schedule_a)\n",
    "    svm.train(train_X, train_y)\n",
    "    print('C {}: weights = {}'.format(c,svm.weights))\n",
    "    train_errors.append(svm.evaluate(train_X, train_y))\n",
    "    test_errors.append(svm.evaluate(test_X, test_y))\n",
    "print('Training Errors: {}'.format(train_errors))\n",
    "print('Testing Errors: {}'.format(test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_b = lambda t:gamma_0 / (1 + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001145475372279496: weights = [-3.73505563e-01 -1.70655237e-01 -1.45437691e-01 -7.89171176e-02\n",
      "  9.98854525e-06]\n",
      "C 0.011454753722794959: weights = [-7.28630240e-01 -3.68194467e-01 -3.69761376e-01 -1.93643088e-01\n",
      "  9.98854525e-05]\n",
      "C 0.0572737686139748: weights = [-1.10445012e+00 -5.89441091e-01 -6.33769389e-01 -2.47590179e-01\n",
      "  4.99427262e-04]\n",
      "C 0.1145475372279496: weights = [-1.26426257e+00 -6.76874543e-01 -7.32126995e-01 -2.82249291e-01\n",
      "  9.98854525e-04]\n",
      "C 0.3436426116838488: weights = [-1.58527834 -0.85788808 -0.90598141 -0.33869477  0.00299656]\n",
      "C 0.572737686139748: weights = [-1.72428192 -0.96253544 -1.05129922 -0.35398384  0.00499427]\n",
      "C 0.8018327605956472: weights = [-1.88370336 -1.07649151 -1.07785222 -0.39328958  0.00699198]\n",
      "Training Errors: [5.045871559633028, 4.128440366972478, 4.013761467889909, 4.013761467889909, 3.89908256880734, 3.89908256880734, 3.89908256880734]\n",
      "Testing Errors: [7.199999999999999, 4.8, 4.6, 4.6, 4.8, 4.8, 5.2]\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "for c in C_list:\n",
    "    svm = SVM(4, 100, c, schedule_b)\n",
    "    svm.train(train_X, train_y)\n",
    "    print('C {}: weights = {}'.format(c,svm.weights))\n",
    "    train_errors.append(svm.evaluate(train_X, train_y))\n",
    "    test_errors.append(svm.evaluate(test_X, test_y))\n",
    "print('Training Errors: {}'.format(train_errors))\n",
    "print('Testing Errors: {}'.format(test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-2.04253733 -1.28008058 -1.5132451  -0.24830283  2.18696284]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dual SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual Form SVM:\n",
    "\n",
    "$$ \\min_{\\{ 0 \\le \\alpha_i \\le C \\}, \\sum_i \\alpha_i y_i = 0} \\frac{1}{2} \\sum_i \\sum_j y_i y_j \\alpha_i \\alpha_j {x_i}^T x_j - \\sum_i \\alpha_i $$\n",
    "\n",
    "Dual form with Kernel:\n",
    "\n",
    "$$ \\min_{\\alpha} \\frac{1}{2} \\sum_i \\sum_j y_i y_j \\alpha_i \\alpha_j K(x_i, x_j) - \\sum_i \\alpha_i $$\n",
    "\n",
    "$$s.t. \\ 0 \\le \\alpha_i \\le C $$\n",
    "$$ \\ \\ \\ \\ \\ \\sum_i \\alpha_i y_i = 0 $$\n",
    "\n",
    "**Converting to Matrix notation:**\n",
    "\n",
    "H is a matrix such that $H_{i,j} = y_i y_j K(x_i,x_j)$\n",
    "\n",
    "We now convert the sums into vectors:\n",
    "\n",
    "$$ \\min_{\\alpha} \\frac{1}{2} \\alpha^T \\bf H \\alpha -  1^T \\alpha $$\n",
    "\n",
    "$$s.t. \\ 0 \\le \\alpha_i \\le C $$\n",
    "$$ \\ \\ \\ \\ \\ y^T \\alpha = 0 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXOPT QP Solver:\n",
    "\n",
    "$$ \\min_x \\frac{1}{2} x^T P x - q^T x $$\n",
    "$$ s.t. Gx \\le h $$\n",
    "$$ and Ax = b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to cvxopt format:\n",
    "\n",
    "$ P = H $ matrix (mxm)\n",
    "\n",
    "$ q = -1 $ vector (mx1)\n",
    "\n",
    "G =  (2mxm) matrix, first 3 rows are $ 0 \\le \\alpha $ constraint, last 3 are $ \\alpha \\le C $ constraint\n",
    "\n",
    " h =  vector (2mx1) , first 3 elements are 0, last three elements o\n",
    "\n",
    "$ A = y $ labels vector (mx1) \n",
    "\n",
    "$ b = 0 $ scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(gamma=0.5):\n",
    "    return lambda x,y: np.exp(-np.linalg.norm(x-y)**2 / gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualSVM(object):\n",
    "\n",
    "    def __init__(self, C, kernel=linear_kernel):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        if self.kernel == linear_kernel:\n",
    "            return  np.sign(np.dot(inputs, self.weights[:-1]) + self.weights[-1])\n",
    "        else:\n",
    "            result = 0\n",
    "            for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                result += a * sv_y * self.kernel(inputs, sv)\n",
    "            \n",
    "            return np.sign(result).item()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Kernel Matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = self.kernel(X[i], X[j])\n",
    "                \n",
    "        P = cvxopt.matrix(np.outer(y,y)*K)\n",
    "        q = cvxopt.matrix(-1*np.ones(n_samples))\n",
    "        G = cvxopt.matrix(np.vstack((np.diag(-1*np.ones(n_samples)), np.identity(n_samples))))\n",
    "        h = cvxopt.matrix(np.hstack((np.zeros(n_samples),self.C*np.ones(n_samples))))\n",
    "        A = cvxopt.matrix(y, (1,n_samples), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        \n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        cvxopt.solvers.options['abstol'] = 1e-10\n",
    "        cvxopt.solvers.options['reltol'] = 1e-10\n",
    "        cvxopt.solvers.options['feastol'] = 1e-10\n",
    "        \n",
    "        # Quadratic Programming solution from cvxopt\n",
    "        sol = cvxopt.solvers.qp(P,q,G,h,A,b)\n",
    "        \n",
    "        # Lagrange Multipliers\n",
    "        alphas = np.array(sol['x'])\n",
    "        \n",
    "        # weights\n",
    "        w = ((y * alphas).T @ X).reshape(-1,1)\n",
    "        # non-zero alphas\n",
    "        S = (alphas > 1e-4).flatten()\n",
    "        self.S = S\n",
    "        self.n_supports = np.sum(S)\n",
    "        # intercept\n",
    "        b = y[S] - np.dot(X[S], w)\n",
    "        \n",
    "        ind = np.arange(len(alphas))[S]\n",
    "        self.a = alphas[S]\n",
    "        self.sv = X[S]\n",
    "        \n",
    "        self.sv_y = y[S]\n",
    "        \n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += float(self.sv_y[n])\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],S])\n",
    "        self.b /= len(self.a)\n",
    "        \n",
    "        self.weights = np.zeros(n_features + 1)\n",
    "        self.weights[:-1] = w.flatten()\n",
    "        self.weights[-1] = b[0]\n",
    "                \n",
    "    def evaluate(self, X, y):\n",
    "        # calculates average prediction error on dataset, in percentage\n",
    "        errors = []\n",
    "        for inputs, label in zip(X, y):\n",
    "            prediction = self.predict(inputs)\n",
    "            if np.sign(prediction) != label:\n",
    "                errors.append(1)\n",
    "            else:\n",
    "                errors.append(0)\n",
    "        \n",
    "        return 100*(sum(errors) / float(X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [100.0/873, 500.0/873, 700.0/873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.1145475372279496: weights = [-0.94303948 -0.65147876 -0.73370349 -0.04098535  1.52256115]\n",
      "C 0.572737686139748: weights = [-1.56426251 -1.0137622  -1.18050792 -0.15618296  1.91748011]\n",
      "C 0.8018327605956472: weights = [-2.04253733 -1.28008058 -1.5132451  -0.24830283  2.18696284]\n",
      "[1.4908256880733946, 0.8027522935779817, 0.8027522935779817] [1.4000000000000001, 0.8, 0.8]\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing errors for each C value\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "for c in C:\n",
    "    svm = DualSVM(c,kernel=linear_kernel)\n",
    "    svm.train(train_X,train_y)\n",
    "    print('C {}: weights = {}'.format(c,svm.weights))\n",
    "    train_errors.append(svm.evaluate(train_X,train_y))\n",
    "    test_errors.append(svm.evaluate(test_X,test_y))\n",
    "print(train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_list = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0] [0.2, 0.2, 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing errors for each C value\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "for c in C:\n",
    "    svm = DualSVM(c,kernel=gaussian_kernel())\n",
    "    svm.train(train_X,train_y)\n",
    "    train_errors.append(svm.evaluate(train_X,train_y))\n",
    "    test_errors.append(svm.evaluate(test_X,test_y))\n",
    "print(train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma 0.01: [0.0, 0.0, 0.0], [0.2, 0.2, 0.2]\n",
      "Gamma 0.1: [0.0, 0.0, 0.0], [0.2, 0.2, 0.2]\n",
      "Gamma 0.5: [0.0, 0.0, 0.0], [0.2, 0.2, 0.2]\n",
      "Gamma 1: [0.0, 0.0, 0.0], [0.2, 0.2, 0.2]\n",
      "Gamma 2: [0.0, 0.0, 0.0], [0.2, 0.2, 0.2]\n",
      "Gamma 5: [0.8027522935779817, 0.0, 0.0], [0.6, 0.2, 0.2]\n",
      "Gamma 10: [0.8027522935779817, 0.0, 0.0], [0.6, 0.2, 0.2]\n",
      "Gamma 100: [0.34403669724770647, 0.0, 0.0], [0.4, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for g in gamma_list:\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for c in C:\n",
    "        svm = DualSVM(c,kernel=gaussian_kernel(g))\n",
    "        svm.train(train_X,train_y)\n",
    "        train_errors.append(svm.evaluate(train_X,train_y))\n",
    "        test_errors.append(svm.evaluate(test_X,test_y))\n",
    "    print('Gamma {}: {}, {}'.format(g,train_errors, test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Supports: [872, 872, 872]\n",
      "N Supports: [869, 868, 864]\n",
      "N Supports: [825, 730, 689]\n",
      "N Supports: [805, 555, 519]\n",
      "N Supports: [693, 389, 359]\n",
      "N Supports: [442, 208, 193]\n",
      "N Supports: [316, 130, 114]\n",
      "N Supports: [290, 116, 98]\n"
     ]
    }
   ],
   "source": [
    "for g in gamma_list:\n",
    "    supports = []\n",
    "    for c in C:\n",
    "        svm = DualSVM(c,kernel=gaussian_kernel(g))\n",
    "        svm.train(train_X,train_y)\n",
    "        supports.append(svm.n_supports)\n",
    "        #train_errors.append(svm.evaluate(train_X,train_y))\n",
    "        #test_errors.append(svm.evaluate(test_X,test_y))\n",
    "    print('N Supports: {}'.format(supports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = []\n",
    "for g in gamma_list:\n",
    "    svm = DualSVM(500/873,kernel=gaussian_kernel(g))\n",
    "    svm.train(train_X,train_y)\n",
    "    supports.append(svm.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[868, 730, 552, 379, 194, 122, 64]\n"
     ]
    }
   ],
   "source": [
    "overlap_supports = []\n",
    "for i in range(7):\n",
    "    overlap_supports.append(np.sum(np.logical_and(supports[i], supports[i+1])))\n",
    "print(overlap_supports)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
