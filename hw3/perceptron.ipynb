{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "## Machine Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 4 attributions (the first 4 columns)\n",
    "\n",
    "1. variance of Wavelet Transformed image (continuous) \n",
    "2. skewness of Wavelet Transformed image (continuous) \n",
    "3. curtosis of Wavelet Transformed image (continuous) \n",
    "4. entropy of image (continuous) \n",
    "\n",
    "The label is the last column: genuine or forged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('bank-note/test.csv', header=None)\n",
    "train_data = pd.read_csv('bank-note/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.848100</td>\n",
       "      <td>10.15390</td>\n",
       "      <td>-3.85610</td>\n",
       "      <td>-4.22280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.004700</td>\n",
       "      <td>0.45937</td>\n",
       "      <td>1.36210</td>\n",
       "      <td>1.61810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-1.60370</td>\n",
       "      <td>8.47560</td>\n",
       "      <td>0.75558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266700</td>\n",
       "      <td>2.81830</td>\n",
       "      <td>-2.42600</td>\n",
       "      <td>-1.88620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.203400</td>\n",
       "      <td>5.99470</td>\n",
       "      <td>0.53009</td>\n",
       "      <td>0.84998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2        3  4\n",
       "0  3.848100  10.15390 -3.85610 -4.22280  0\n",
       "1  4.004700   0.45937  1.36210  1.61810  0\n",
       "2 -0.048008  -1.60370  8.47560  0.75558  0\n",
       "3 -1.266700   2.81830 -2.42600 -1.88620  1\n",
       "4  2.203400   5.99470  0.53009  0.84998  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 7 columns are features, last column (Slump) is output\n",
    "columns = ['var', 'skew', 'curt', 'ent', 'label']\n",
    "features = columns[:-1]\n",
    "output = columns[-1]\n",
    "\n",
    "test_data.columns = columns\n",
    "train_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>curt</th>\n",
       "      <th>ent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.848100</td>\n",
       "      <td>10.15390</td>\n",
       "      <td>-3.85610</td>\n",
       "      <td>-4.22280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.004700</td>\n",
       "      <td>0.45937</td>\n",
       "      <td>1.36210</td>\n",
       "      <td>1.61810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-1.60370</td>\n",
       "      <td>8.47560</td>\n",
       "      <td>0.75558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266700</td>\n",
       "      <td>2.81830</td>\n",
       "      <td>-2.42600</td>\n",
       "      <td>-1.88620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.203400</td>\n",
       "      <td>5.99470</td>\n",
       "      <td>0.53009</td>\n",
       "      <td>0.84998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        var      skew     curt      ent  label\n",
       "0  3.848100  10.15390 -3.85610 -4.22280      0\n",
       "1  4.004700   0.45937  1.36210  1.61810      0\n",
       "2 -0.048008  -1.60370  8.47560  0.75558      0\n",
       "3 -1.266700   2.81830 -2.42600 -1.88620      1\n",
       "4  2.203400   5.99470  0.53009  0.84998      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train_data.iloc[:,:-1].values\n",
    "test_inputs = test_data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data.iloc[:,-1].values\n",
    "test_labels = test_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A) Standard Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, epoch=10, rate=0.01):\n",
    "        self.epoch = epoch\n",
    "        self.rate = rate   # learning rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)  # initialize weights to zero\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, train_inputs, labels):\n",
    "        # trains perceptron weights on training dataset\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "        data = np.hstack((train_inputs,labels))\n",
    "        for e in range(self.epoch):\n",
    "            #print(\"Epoch: \"+ str(e))\n",
    "            #print(\"Weights: \" + str(self.weights))\n",
    "            np.random.shuffle(data)\n",
    "            for row in data:\n",
    "                inputs = row[:-1]\n",
    "                label = row[-1]\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.rate * (label - prediction)\n",
    "                \n",
    "        return self.weights\n",
    "                \n",
    "    def evaluate(self, test_inputs, labels):\n",
    "        # calculates average prediction error on testing dataset\n",
    "        errors = []\n",
    "        for inputs, label in zip(test_inputs, labels):\n",
    "            prediction = self.predict(inputs)\n",
    "            errors.append(np.abs(label-prediction))\n",
    "        \n",
    "        return sum(errors) / float(test_inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52      , -0.59570448, -0.3630103 , -0.41950593, -0.06221142])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.train(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011467889908256881"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5609     -0.59135312 -0.38124022 -0.40615604 -0.09201845]\n",
      "0.023100000000000006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    perceptron = Perceptron(4)\n",
    "    weights.append(perceptron.train(train_inputs, train_labels))\n",
    "    errors.append(perceptron.evaluate(test_inputs, test_labels))\n",
    "    \n",
    "print(np.mean(weights, axis=0)), print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B) Voted Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotedPerceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, epoch=10, rate=0.01):\n",
    "        self.epoch = epoch\n",
    "        self.rate = rate   # learning rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)  # initialize weights to zero\n",
    "        #self.weights_set = [np.zeros(no_of_inputs + 1)]\n",
    "        self.C = [0]\n",
    "        \n",
    "    def predict(self, inputs, weights):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        summation = np.dot(inputs, weights[1:]) + weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, train_inputs, labels):\n",
    "        # trains perceptron weights on training dataset\n",
    "        weights = np.zeros(train_inputs.shape[1] + 1)\n",
    "        weights_set = [np.zeros(train_inputs.shape[1]+1)]\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "        data = np.hstack((train_inputs,labels))\n",
    "        m = 0\n",
    "        for e in range(self.epoch):\n",
    "            #print(\"Epoch: \"+ str(e))\n",
    "            \n",
    "            np.random.shuffle(data)\n",
    "            for row in data:\n",
    "                inputs = row[:-1]\n",
    "                label = row[-1]\n",
    "                prediction = self.predict(inputs, weights)\n",
    "                error = label - prediction\n",
    "                if error:\n",
    "                    #weights_a = self.rate * (label - prediction) * inputs\n",
    "                    #weights_b = self.rate * (label - prediction)\n",
    "                    #self.weights[1:] += weights_a\n",
    "                    #self.weights[0] += weights_b\n",
    "                    weights[1:] += self.rate * (label - prediction) * inputs\n",
    "                    weights[0] += self.rate * (label - prediction)\n",
    "                    #print('Error!')\n",
    "                    #print(weights)\n",
    "                    weights_set.append(np.copy(weights))\n",
    "                    \n",
    "                    self.C.append(1)\n",
    "                    m += 1\n",
    "                    \n",
    "                else:\n",
    "                    self.C[m] += 1\n",
    "                    \n",
    "        self.weights = weights\n",
    "        self.weights_set = weights_set\n",
    "        \n",
    "        return self.weights\n",
    "                \n",
    "    \n",
    "    def evaluate(self, test_inputs, labels):\n",
    "        # calculates average prediction error on testing dataset\n",
    "        errors = []\n",
    "        n_weights = len(self.weights_set)\n",
    "        for inputs, label in zip(test_inputs, labels):\n",
    "            predictions = []\n",
    "            for k in range(n_weights):\n",
    "                pred = self.predict(inputs, weights=self.weights_set[k])\n",
    "                if not pred:\n",
    "                    pred = -1\n",
    "                predictions.append(self.C[k]*pred)\n",
    "                \n",
    "            prediction = np.sign(sum(predictions))\n",
    "            if prediction == -1:\n",
    "                prediction = 0\n",
    "            \n",
    "            errors.append(np.abs(label-prediction))\n",
    "        \n",
    "        return sum(errors) / float(test_inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54      , -0.57252862, -0.34178077, -0.44049389, -0.1817347 ])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = VotedPerceptron(4)\n",
    "perceptron.train(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011467889908256881"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(train_inputs, train_labels)\n",
    "perceptron.evaluate(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5609     -0.59851385 -0.37898256 -0.41597761 -0.09158596]\n",
      "0.013760000000000003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    perceptron = VotedPerceptron(4)\n",
    "    weights.append(perceptron.train(train_inputs, train_labels))\n",
    "    errors.append(perceptron.evaluate(test_inputs, test_labels))\n",
    "    \n",
    "print(np.mean(weights, axis=0)), print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C) Average Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPerceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, epoch=10, rate=0.01):\n",
    "        self.epoch = epoch\n",
    "        self.rate = rate   # learning rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)  # initialize weights to zero\n",
    "        #self.weights_set = [np.zeros(no_of_inputs + 1)]\n",
    "        self.a = np.zeros(no_of_inputs + 1)\n",
    "        \n",
    "    def predict(self, inputs, weights):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        summation = np.dot(inputs, weights[1:]) + weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, train_inputs, labels):\n",
    "        # trains perceptron weights on training dataset\n",
    "        weights = np.zeros(train_inputs.shape[1] + 1)\n",
    "        weights_set = [np.zeros(train_inputs.shape[1]+1)]\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "        data = np.hstack((train_inputs,labels))\n",
    "        m = 0\n",
    "        for e in range(self.epoch):\n",
    "            #print(\"Epoch: \"+ str(e))\n",
    "            \n",
    "            np.random.shuffle(data)\n",
    "            for row in data:\n",
    "                inputs = row[:-1]\n",
    "                label = row[-1]\n",
    "                prediction = self.predict(inputs, weights)\n",
    "                error = label - prediction\n",
    "                weights[1:] += self.rate * (label - prediction) * inputs\n",
    "                weights[0] += self.rate * (label - prediction)\n",
    "                self.a += np.copy(weights)\n",
    "                    \n",
    "\n",
    "        self.weights = weights\n",
    "        \n",
    "        return self.a\n",
    "    \n",
    "    def evaluate(self, test_inputs, labels):\n",
    "        # calculates average prediction error on testing dataset\n",
    "        errors = []\n",
    "        for inputs, label in zip(test_inputs, labels):\n",
    "            prediction = self.predict(inputs, weights=self.a)\n",
    "            errors.append(np.abs(label-prediction))\n",
    "        \n",
    "        return sum(errors) / float(test_inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3358.96      , -3921.94546045, -2562.311736  , -2656.91071295,\n",
       "        -884.42353634])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = AvgPerceptron(4)\n",
    "perceptron.train(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01261467889908257"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.evaluate(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3437.8202     -3980.81967769 -2591.51978412 -2681.63009231\n",
      "  -752.43529268]\n",
      "0.013860000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    perceptron = AvgPerceptron(4)\n",
    "    weights.append(perceptron.train(train_inputs, train_labels))\n",
    "    errors.append(perceptron.evaluate(test_inputs, test_labels))\n",
    "    \n",
    "print(np.mean(weights, axis=0)), print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### D) Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
