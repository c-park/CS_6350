{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.4 Least Mean Squares\n",
    "#### CS 6350: HW 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[22 points] We will implement the LMS method for a linear regression task. The dataset\n",
    "is from UCI repository (https://archive.ics.uci.edu/ml/datasets/Concrete+Slump+Test). The task is to predict the real-valued SLUMP of the concrete, with 7 features.\n",
    "The features and output are listed in the file “concrete/data-desc.txt”. The training data are stored in the file “concrete/train.csv”, consisting of 53 examples. The\n",
    "test data are stored in “concrete/test.csv”, and comprise of 50 examples. In both the\n",
    "training and testing datasets, feature values and outputs are separated by commas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "#plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('concrete/test.csv', header=None)\n",
    "train_data = pd.read_csv('concrete/train.csv', header=None)\n",
    "\n",
    "# first 7 columns are features, last column (Slump) is output\n",
    "columns = ['Cement', 'Slag', 'Fly ash', 'Water','SP', 'Coarse Aggr', 'Fine Aggr', 'Slump']\n",
    "features = columns[:-1]\n",
    "output = columns[-1]\n",
    "\n",
    "test_data.columns = columns\n",
    "train_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr</th>\n",
       "      <th>Fine Aggr</th>\n",
       "      <th>Slump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.890447</td>\n",
       "      <td>-1.295950</td>\n",
       "      <td>1.188030</td>\n",
       "      <td>-1.450430</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1.876070</td>\n",
       "      <td>-0.818684</td>\n",
       "      <td>-0.005574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549165</td>\n",
       "      <td>0.066917</td>\n",
       "      <td>-0.517804</td>\n",
       "      <td>0.638098</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>0.227616</td>\n",
       "      <td>-0.945600</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941555</td>\n",
       "      <td>-1.292630</td>\n",
       "      <td>1.068030</td>\n",
       "      <td>1.950890</td>\n",
       "      <td>-0.085833</td>\n",
       "      <td>-1.180960</td>\n",
       "      <td>-0.385584</td>\n",
       "      <td>0.798260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966886</td>\n",
       "      <td>1.047520</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>1.831540</td>\n",
       "      <td>0.880569</td>\n",
       "      <td>-0.988829</td>\n",
       "      <td>-0.898007</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.638344</td>\n",
       "      <td>0.233121</td>\n",
       "      <td>-0.364867</td>\n",
       "      <td>0.488917</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.961465</td>\n",
       "      <td>0.855677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement      Slag   Fly ash     Water        SP  Coarse Aggr  Fine Aggr  \\\n",
       "0 -0.890447 -1.295950  1.188030 -1.450430  1.238500     1.876070  -0.818684   \n",
       "1  0.549165  0.066917 -0.517804  0.638098  0.164716     0.227616  -0.945600   \n",
       "2  0.941555 -1.292630  1.068030  1.950890 -0.085833    -1.180960  -0.385584   \n",
       "3 -0.966886  1.047520  0.376289  1.831540  0.880569    -0.988829  -0.898007   \n",
       "4  0.638344  0.233121 -0.364867  0.488917  0.164716    -0.011126  -0.961465   \n",
       "\n",
       "      Slump  \n",
       "0 -0.005574  \n",
       "1  0.568593  \n",
       "2  0.798260  \n",
       "3  0.568593  \n",
       "4  0.855677  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53, 8), (50, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = train_data.iloc[:,:-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.605170185988092"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A. Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [8 points] Implement the batch gradient descent algorithm, and tune the learning\n",
    "rate r to ensure the algorithm converges. To examine convergence, you can watch\n",
    "the norm of the weight vector difference, kwt−wt−1k, at each step t. if kwt−wt−1k\n",
    "is less than a tolerance level, say, 1e − 6, you can conclude that it converges. You\n",
    "can initialize your weight vector to be 0. Please find an appropriate r such that\n",
    "the algorithm converges. To tune r, you can start with a relatively big value,\n",
    "say, r = 1, and then gradually decrease r, say r = 0.5, 0.25, 0.125, . . ., until you\n",
    "see the convergence. Report the learned weight vector, and the learning rate r.\n",
    "Meanwhile, please record the cost function value of the training data at each step,\n",
    "and then draw a figure shows how the cost function changes along with steps. Use\n",
    "your final weight vector to calculate the cost function value of the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdc_method(A,b, epsilon, t=0.01):\n",
    "    \"\"\" Batch Gradient Descent Method\n",
    "    \n",
    "    Args:\n",
    "        A (mxn numpy array): input array holding m samples with n features\n",
    "        b (mx1 numpy array): output \n",
    "        epsilon (float): tolerance level\n",
    "        t (float): learning rate\n",
    "\n",
    "    Returns:\n",
    "        tree (dict): dictionary structure represented the decision tree\n",
    "  \n",
    "    \"\"\"\n",
    "    x = np.zeros(A.shape[1])\n",
    "    \n",
    "    diff = 1\n",
    "\n",
    "    iter=0\n",
    "    fun_val=f(A,b,x)\n",
    "    fun_history = fun_val\n",
    "    \n",
    "    grad=g(A,b,x)\n",
    "    while (np.linalg.norm(diff)>epsilon):\n",
    "        iter=iter+1\n",
    "        \n",
    "        # break out of while loop if diverging\n",
    "        if np.linalg.norm(diff)>1e20:\n",
    "            break\n",
    "  \n",
    "        # define new point x = x + t d, d = - grad\n",
    "        x_new=x-t*grad\n",
    "        diff = x_new - x\n",
    "        x = x_new\n",
    "\n",
    "        fun_val= f(A,b,x)\n",
    "        fun_history = np.vstack((fun_history,fun_val))\n",
    "        grad = g(A,b,x)\n",
    "        #if iter % 100 == 0:\n",
    "            #print('iter_number = {}, tol = {:.4e}, fun_val = {:.4e}'.format(iter, np.linalg.norm(diff), fun_val))\n",
    "        \n",
    "    if np.linalg.norm(diff)>1e20:\n",
    "        iter = None\n",
    "        print('Algorithm does not converge!')\n",
    "    print('iter_number = {}, tol = {:.4e}, fun_val = {:.4e}'.format(iter, np.linalg.norm(diff), fun_val))\n",
    "    return x, fun_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(A,b, x):\n",
    "    \"\"\" Calculates the loss funtion value\n",
    "    \"\"\"\n",
    "    val = 0.0\n",
    "    \n",
    "    for i in range(A.shape[0]):\n",
    "        val += (b[i] - x@A[i,:])**2\n",
    "        \n",
    "    return val / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(A,b, x):\n",
    "    \"\"\" Calculates the gradient\n",
    "    \"\"\"\n",
    "    grad = np.zeros(x.shape)\n",
    "    \n",
    "    for j in range(len(grad)):\n",
    "        for i in range(A.shape[0]):\n",
    "            grad[j] += (b[i] - x@A[i,:])*A[i,j]\n",
    "        \n",
    "    return - grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_array = train_data.to_numpy()\n",
    "\n",
    "A = train_data_array[:,:-1]\n",
    "A = np.insert(A,0,np.ones(A.shape[0]), axis=1)\n",
    "\n",
    "b = train_data_array[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53, 8), (53,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, fh = gradient_method(A,b, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7095, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(fh)),fh, s=3)\n",
    "plt.title('Cost function vs Time')\n",
    "plt.xlabel('Iteration #')\n",
    "plt.ylabel('Cost Function Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125, 0.015625, 0.0078125]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates = [1/(2**i) for i in range(8)]\n",
    "\n",
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 2.1795e+20, fun_val = 3.1189e+42\n"
     ]
    }
   ],
   "source": [
    "x1, fh1 = batch_gradient_method(A,b, epsilon,t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 8.5691e+20, fun_val = 4.7487e+43\n"
     ]
    }
   ],
   "source": [
    "x2, fh2 = batch_gradient_method(A,b, epsilon,t=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 1.8467e+20, fun_val = 2.1388e+42\n"
     ]
    }
   ],
   "source": [
    "x3, fh3 = batch_gradient_method(A,b, epsilon,t=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 4.5099e+20, fun_val = 1.1979e+43\n"
     ]
    }
   ],
   "source": [
    "x4, fh4 = batch_gradient_method(A,b, epsilon,t=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 6.3839e+20, fun_val = 2.1036e+43\n"
     ]
    }
   ],
   "source": [
    "x5, fh5 = batch_gradient_method(A,b, epsilon,t=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 1.8178e+20, fun_val = 1.2720e+42\n"
     ]
    }
   ],
   "source": [
    "x6, fh6 = batch_gradient_method(A,b, epsilon,t=0.03125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm does not converge!\n",
      "iter_number = None, tol = 1.0038e+20, fun_val = 1.8157e+41\n"
     ]
    }
   ],
   "source": [
    "x7, fh7 = batch_gradient_method(A,b, epsilon,t=0.015625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_number = 8800, tol = 9.9976e-07, fun_val = 1.4982e+01\n"
     ]
    }
   ],
   "source": [
    "x8, fh8 = batch_gradient_method(A,b, epsilon,t=0.0078125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_number = 7094, tol = 9.9916e-07, fun_val = 1.4982e+01\n"
     ]
    }
   ],
   "source": [
    "x9, fh9 = batch_gradient_method(A,b, epsilon,t=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your final weight vector to calculate the cost function value of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.98194366])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cost function on training data\n",
    "fh9[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_array = test_data.to_numpy()\n",
    "\n",
    "A_test = test_data_array[:,:-1]\n",
    "A_test = np.insert(A_test,0,np.ones(A_test.shape[0]), axis=1)\n",
    "\n",
    "b_test = test_data_array[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.36175759033997"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cost funtion on test data\n",
    "f(A_test,b_test, x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [8 points] Implement the stochastic gradient descent (SGD) algorithm. You can\n",
    "initialize your weight vector to be 0. Each step, you randomly sample a training\n",
    "example, and then calculate the stochastic gradient to update the weight vector.\n",
    "Tune the learning rate r to ensure your SGD converges. To check convergence, you\n",
    "can calculate the cost function of the training data after each stochastic gradient\n",
    "update, and draw a figure showing how the cost function values vary along with\n",
    "the number of updates. At the beginning, your curve will oscillate a lot. However,\n",
    "with an appropriate r, as more and more updates are finished, you will see the\n",
    "cost function tends to converge. Please report the learned weight vector, and the\n",
    "learning rate you chose, and the cost function value of the test data with your\n",
    "learned weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 8)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_method(df, attrs, target_attr, epsilon, t=0.01):\n",
    "    \"\"\" Stochastic Gradient Descent Method\n",
    "    \n",
    "    Args:\n",
    "        A (mxn numpy array): input array holding m samples with n features\n",
    "        b (mx1 numpy array): output \n",
    "        epsilon (float): tolerance level\n",
    "        t (float): learning rate\n",
    "\n",
    "    Returns:\n",
    "        tree (dict): dictionary structure represented the decision tree\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    m,n = df.shape\n",
    "    \n",
    "    # convert to numpy array\n",
    "    data = df.to_numpy()\n",
    "    \n",
    "    # Separate to Ax=b where A is input matrix, x is vector of weights, and b the vector of outputs\n",
    "    A = data[:,:-1]\n",
    "    A = np.insert(A,0,np.ones(m), axis=1)\n",
    "    b = data[:,-1] \n",
    "    x = np.zeros(n)\n",
    "\n",
    "    iter=0\n",
    "    max_iter = 20000\n",
    "    cur_val=100\n",
    "    prev_val = np.inf\n",
    "    history = cur_val\n",
    "    \n",
    "    while np.linalg.norm(prev_val-cur_val) > epsilon and iter < max_iter:\n",
    "        iter = iter + 1\n",
    "        prev_val = cur_val\n",
    "        \n",
    "        # shuffle indexes for sampling\n",
    "        indexes = np.random.randint(m, size=m)\n",
    "        \n",
    "        for i in indexes:\n",
    "            # define new point x = x + t d, d = - grad\n",
    "            x = x + t*(b[i] - np.dot(x,A[i]))*A[i]\n",
    "\n",
    "        cur_val= f(A,b,x)\n",
    "        history = np.vstack((history,cur_val))\n",
    "            \n",
    "        \n",
    "        #print('i = {}, tol = {:.4e}, fun_val = {:.4e}'.format(iter, np.linalg.norm(prev_val-cur_val), cur_val))\n",
    "        \n",
    "    print('i = {}, tol = {:.4e}, fun_val = {:.4e}'.format(iter, np.linalg.norm(prev_val-cur_val), cur_val))\n",
    "    return x, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(100-0) < epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 3497, tol = 2.1769e-07, fun_val = 1.6266e+01\n"
     ]
    }
   ],
   "source": [
    "x_b, h_b = sgd_method(data, features, output, epsilon,t=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.random.randint(len(train_data), size=len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr</th>\n",
       "      <th>Fine Aggr</th>\n",
       "      <th>Slump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.890447</td>\n",
       "      <td>-1.295950</td>\n",
       "      <td>1.188030</td>\n",
       "      <td>-1.450430</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1.876070</td>\n",
       "      <td>-0.818684</td>\n",
       "      <td>-0.005574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549165</td>\n",
       "      <td>0.066917</td>\n",
       "      <td>-0.517804</td>\n",
       "      <td>0.638098</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>0.227616</td>\n",
       "      <td>-0.945600</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941555</td>\n",
       "      <td>-1.292630</td>\n",
       "      <td>1.068030</td>\n",
       "      <td>1.950890</td>\n",
       "      <td>-0.085833</td>\n",
       "      <td>-1.180960</td>\n",
       "      <td>-0.385584</td>\n",
       "      <td>0.798260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966886</td>\n",
       "      <td>1.047520</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>1.831540</td>\n",
       "      <td>0.880569</td>\n",
       "      <td>-0.988829</td>\n",
       "      <td>-0.898007</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.638344</td>\n",
       "      <td>0.233121</td>\n",
       "      <td>-0.364867</td>\n",
       "      <td>0.488917</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.961465</td>\n",
       "      <td>0.855677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement      Slag   Fly ash     Water        SP  Coarse Aggr  Fine Aggr  \\\n",
       "0 -0.890447 -1.295950  1.188030 -1.450430  1.238500     1.876070  -0.818684   \n",
       "1  0.549165  0.066917 -0.517804  0.638098  0.164716     0.227616  -0.945600   \n",
       "2  0.941555 -1.292630  1.068030  1.950890 -0.085833    -1.180960  -0.385584   \n",
       "3 -0.966886  1.047520  0.376289  1.831540  0.880569    -0.988829  -0.898007   \n",
       "4  0.638344  0.233121 -0.364867  0.488917  0.164716    -0.011126  -0.961465   \n",
       "\n",
       "      Slump  \n",
       "0 -0.005574  \n",
       "1  0.568593  \n",
       "2  0.798260  \n",
       "3  0.568593  \n",
       "4  0.855677  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_data.sample(frac=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr</th>\n",
       "      <th>Fine Aggr</th>\n",
       "      <th>Slump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.852227</td>\n",
       "      <td>1.180480</td>\n",
       "      <td>0.493932</td>\n",
       "      <td>-0.853710</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>-0.465871</td>\n",
       "      <td>0.101456</td>\n",
       "      <td>-2.072580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.903186</td>\n",
       "      <td>-1.295950</td>\n",
       "      <td>1.164500</td>\n",
       "      <td>-1.102350</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1.785120</td>\n",
       "      <td>-0.898007</td>\n",
       "      <td>0.338926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.867663</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>-1.753060</td>\n",
       "      <td>-0.555349</td>\n",
       "      <td>-0.909064</td>\n",
       "      <td>-0.056600</td>\n",
       "      <td>1.196110</td>\n",
       "      <td>-1.728080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.182107</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>1.058620</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>-0.407967</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-1.435810</td>\n",
       "      <td>1.085340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.142700</td>\n",
       "      <td>-0.551360</td>\n",
       "      <td>1.010390</td>\n",
       "      <td>-1.286330</td>\n",
       "      <td>-1.088030</td>\n",
       "      <td>1.860150</td>\n",
       "      <td>-0.564853</td>\n",
       "      <td>0.626010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement      Slag   Fly ash     Water        SP  Coarse Aggr  Fine Aggr  \\\n",
       "9  -0.852227  1.180480  0.493932 -0.853710  1.238500    -0.465871   0.101456   \n",
       "46 -0.903186 -1.295950  1.164500 -1.102350  1.238500     1.785120  -0.898007   \n",
       "49  0.867663  0.482426 -1.753060 -0.555349 -0.909064    -0.056600   1.196110   \n",
       "7  -0.182107  0.580486  1.058620  0.076184 -0.407967     0.000243  -1.435810   \n",
       "8  -1.142700 -0.551360  1.010390 -1.286330 -1.088030     1.860150  -0.564853   \n",
       "\n",
       "       Slump  \n",
       "9  -2.072580  \n",
       "46  0.338926  \n",
       "49 -1.728080  \n",
       "7   1.085340  \n",
       "8   0.626010  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr</th>\n",
       "      <th>Fine Aggr</th>\n",
       "      <th>Slump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.890447</td>\n",
       "      <td>-1.295950</td>\n",
       "      <td>1.188030</td>\n",
       "      <td>-1.450430</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1.876070</td>\n",
       "      <td>-0.818684</td>\n",
       "      <td>-0.005574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549165</td>\n",
       "      <td>0.066917</td>\n",
       "      <td>-0.517804</td>\n",
       "      <td>0.638098</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>0.227616</td>\n",
       "      <td>-0.945600</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941555</td>\n",
       "      <td>-1.292630</td>\n",
       "      <td>1.068030</td>\n",
       "      <td>1.950890</td>\n",
       "      <td>-0.085833</td>\n",
       "      <td>-1.180960</td>\n",
       "      <td>-0.385584</td>\n",
       "      <td>0.798260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966886</td>\n",
       "      <td>1.047520</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>1.831540</td>\n",
       "      <td>0.880569</td>\n",
       "      <td>-0.988829</td>\n",
       "      <td>-0.898007</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.638344</td>\n",
       "      <td>0.233121</td>\n",
       "      <td>-0.364867</td>\n",
       "      <td>0.488917</td>\n",
       "      <td>0.164716</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.961465</td>\n",
       "      <td>0.855677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement      Slag   Fly ash     Water        SP  Coarse Aggr  Fine Aggr  \\\n",
       "0 -0.890447 -1.295950  1.188030 -1.450430  1.238500     1.876070  -0.818684   \n",
       "1  0.549165  0.066917 -0.517804  0.638098  0.164716     0.227616  -0.945600   \n",
       "2  0.941555 -1.292630  1.068030  1.950890 -0.085833    -1.180960  -0.385584   \n",
       "3 -0.966886  1.047520  0.376289  1.831540  0.880569    -0.988829  -0.898007   \n",
       "4  0.638344  0.233121 -0.364867  0.488917  0.164716    -0.011126  -0.961465   \n",
       "\n",
       "      Slump  \n",
       "0 -0.005574  \n",
       "1  0.568593  \n",
       "2  0.798260  \n",
       "3  0.568593  \n",
       "4  0.855677  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cement', 'Slag', 'Fly ash', 'Water', 'SP', 'Coarse Aggr', 'Fine Aggr']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slump'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoc_gradient_method(train_data, features, output, epsilon, t=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "### C. Optimal weight vector with analytical form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6 points] We have discussed how to calculate the optimal weight vector with an\n",
    "analytical form. Please calculate the optimal weight vector in this way. Comparing with the weight vectors learned by batch gradient descent and stochastic\n",
    "gradient descent, what can you conclude? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
